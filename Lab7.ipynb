{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteracyjne metody rozwiązywania równań liniowych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Czytanka\n",
    "* Kincaid, Cheney, rozdz. 8.2, str. 319 (bardzo przystępnie napisane)\n",
    "* Normy wektorów i macierzy:\n",
    "    * wektorowa: https://en.wikipedia.org/wiki/Norm_(mathematics)\n",
    "    * macierzowa: https://en.wikipedia.org/wiki/Matrix_norm\n",
    "* Metoda Jacobiego: https://en.wikipedia.org/wiki/Jacobi_method\n",
    "* Metoda SOR: https://en.wikipedia.org/wiki/Successive_over-relaxation\n",
    "* Metoda Gaussa-Seidela: https://en.wikipedia.org/wiki/Gauss%E2%80%93Seidel_method\n",
    "* (ale wystarczy K&C)\n",
    "\n",
    "### Troszkę teorii\n",
    "\n",
    "Chcemy rozwiązać układ równań liniowych postaci $A\\mathbf {x} =\\mathbf {b} $, gdzie:\n",
    "\n",
    "$$\n",
    "A={\\begin{bmatrix}a_{11}&a_{12}&\\cdots &a_{1n}\\\\a_{21}&a_{22}&\\cdots &a_{2n}\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\a_{n1}&a_{n2}&\\cdots &a_{nn}\\end{bmatrix}},\\qquad \\mathbf {x} ={\\begin{bmatrix}x_{1}\\\\x_{2}\\\\\\vdots \\\\x_{n}\\end{bmatrix}},\\qquad \\mathbf {b} ={\\begin{bmatrix}b_{1}\\\\b_{2}\\\\\\vdots \\\\b_{n}\\end{bmatrix}}.\n",
    "$$\n",
    "\n",
    "Mimo, że dobrze znamy dokładne metody rozwiązania takiego równania, częstokroć w praktyce nie możemy ich zastosować -- przede wszystkim ze względu na rozmiar problemu. Rozwiązanie? Zastosować metody iteracyjne, które, choć nie dadzą nam dokładnego wyniku, pozwolą nam w rozsądnym czasie uzyskać dobrą aproksymację. (Zresztą, dokładne metody też nie dają dokładnych rezultatów z powodu błędów arytmetyki zmiennoprzecinkowej).\n",
    "\n",
    "_Suchy żarcik dnia: John ma problem. John myśli: \"Wiem, użyję arytmetyki zmiennoprzecinkowej.\" Teraz John ma 1.999999997 problemu. (Zasłyszane w pracy)._\n",
    "\n",
    "\n",
    "#### Metoda Jacobiego\n",
    "\n",
    "Metody Jacobiego możemy użyć pod warunkiem, że macierz jest przekątniowo dominująca, tj. mamy $ |a_{ii}|\\geq \\sum _{j\\neq i}|a_{ij}|\\quad {\\text{dla każdego }}i. $\n",
    "\n",
    "Pomysł polega na rozkładzie macierzy A na **sumę** dwóch macierzy:\n",
    "$$\n",
    "A=D+R\\qquad {\\text{gdzie}}\\qquad D={\\begin{bmatrix}a_{11}&0&\\cdots &0\\\\0&a_{22}&\\cdots &0\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\0&0&\\cdots &a_{nn}\\end{bmatrix}}{\\text{ oraz }}R={\\begin{bmatrix}0&a_{12}&\\cdots &a_{1n}\\\\a_{21}&0&\\cdots &a_{2n}\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\a_{n1}&a_{n2}&\\cdots &0\\end{bmatrix}}.\n",
    "$$\n",
    "\n",
    "Następnie krok iteracji wygląda następująco:\n",
    "$$ \\mathbf {x} ^{(k+1)}=D^{-1}(\\mathbf {b} -R\\mathbf {x} ^{(k)}), $$\n",
    "\n",
    "I element po elemencie:\n",
    "$$ x_{i}^{(k+1)}={\\frac {1}{a_{ii}}}\\left(b_{i}-\\sum _{j\\neq i}a_{ij}x_{j}^{(k)}\\right),\\quad i=1,2,\\ldots ,n. $$\n",
    "\n",
    "Zwróćmy uwagę, że cały trick polega na tym, że macierz $D$ bardzo łatwo odwrócić.\n",
    "\n",
    "### Zadanie 1.\n",
    "Zaimplementować metodę Jacobiego i przetestować jej działanie na paru układach równań. Porównać z metodą eliminacji Gaussa użytą do tych samych równań."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def jacobi_solve(A: np.matrix, b: np.matrix) -> np.matrix:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metoda Gaussa-Seidela\n",
    "\n",
    "Opiera się na tym samym pomyśle, co metoda Jacobiego, ale przy innym rozkładzie macierzy $A$:\n",
    "\n",
    "$$\n",
    "A=L_{*}+U\\qquad {\\text{where}}\\qquad L_{*}={\\begin{bmatrix}a_{11}&0&\\cdots &0\\\\a_{21}&a_{22}&\\cdots &0\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\a_{n1}&a_{n2}&\\cdots &a_{nn}\\end{bmatrix}},\\quad U={\\begin{bmatrix}0&a_{12}&\\cdots &a_{1n}\\\\0&0&\\cdots &a_{2n}\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\0&0&\\cdots &0\\end{bmatrix}}.\n",
    "$$\n",
    "\n",
    "Wtedy układ równań możemy zapisać jako: $ L_{*}\\mathbf {x} =\\mathbf {b} -U\\mathbf {x} $ i iterować tak:\n",
    "\n",
    "$$ \\mathbf {x} ^{(k+1)}=L_{*}^{-1}(\\mathbf {b} -U\\mathbf {x} ^{(k)}). $$\n",
    "\n",
    "Element po elemencie:\n",
    "\n",
    "$$ {\\displaystyle x_{i}^{(k+1)}={\\frac {1}{a_{ii}}}\\left(b_{i}-\\sum _{j=1}^{i-1}a_{ij}x_{j}^{(k+1)}-\\sum _{j=i+1}^{n}a_{ij}x_{j}^{(k)}\\right),\\quad i=1,2,\\dots ,n.} $$\n",
    "\n",
    "Podobnie jak z Jacobim, tutaj trick polega na tym, że macierz L jest łatwa do odwrócenia.\n",
    "\n",
    "### Zadanie 2.\n",
    "Zaimplementować metodę Gaussa-Seidela i przetestować na tych samych układach równań, co metodę Jacobiego. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gauss_seidel_solve(A: np.matrix, b: np.matrix) -> np.matrix:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metoda SOR (Successive Over Relaxation)\n",
    "\n",
    "Znowu podobnie, tyle, że tym razem rozkładamy macierz na sumę trzech macierzy:\n",
    "\n",
    "$$\n",
    "D={\\begin{bmatrix}a_{11}&0&\\cdots &0\\\\0&a_{22}&\\cdots &0\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\0&0&\\cdots &a_{nn}\\end{bmatrix}},\\quad L={\\begin{bmatrix}0&0&\\cdots &0\\\\a_{21}&0&\\cdots &0\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\a_{n1}&a_{n2}&\\cdots &0\\end{bmatrix}},\\quad U={\\begin{bmatrix}0&a_{12}&\\cdots &a_{1n}\\\\0&0&\\cdots &a_{2n}\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\0&0&\\cdots &0\\end{bmatrix}}.\n",
    "$$\n",
    "\n",
    "Co umożliwia zapisanie układu równań tak: $ (D+\\omega L)\\mathbf {x} =\\omega \\mathbf {b} -[\\omega U+(\\omega -1)D]\\mathbf {x} $ i daje następujące wzory na iterację:\n",
    "\n",
    "$$ \\mathbf {x} ^{(k+1)}=(D+\\omega L)^{-1}{\\big (}\\omega \\mathbf {b} -[\\omega U+(\\omega -1)D]\\mathbf {x} ^{(k)}{\\big )}=L_{w}\\mathbf {x} ^{(k)}+\\mathbf {c} , $$\n",
    "\n",
    "oraz:\n",
    "\n",
    "$$ x_{i}^{(k+1)}=(1-\\omega )x_{i}^{(k)}+{\\frac {\\omega }{a_{ii}}}\\left(b_{i}-\\sum _{j<i}a_{ij}x_{j}^{(k+1)}-\\sum _{j>i}a_{ij}x_{j}^{(k)}\\right),\\quad i=1,2,\\ldots ,n. $$\n",
    "\n",
    "### Zadanie 3.\n",
    "Zaimplementować metodę SOR i przetestować na tych samych układach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sor_solve(A: np.matrix, b: np.matrix) -> np.matrix:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 4.\n",
    "Dla powyższych metod porównać (na wykresie) tempo zbiegania do rozwiązania.\n",
    "\n",
    "### Pytanie\n",
    "Jakie jest kryterium zbieżności metod powyżej? Czy zawsze można je stosować?\n",
    "\n",
    "#### Bonus:\n",
    "Jak przeklejać piękne wzory z Wikipedii i się przy tym nie namęczyć? (na zajęciach)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
